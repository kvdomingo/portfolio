---
title: "Activity 12: Feature Extraction"
keywords:
  - image processing
  - computer vision
  - feature extraction
cover: "svip/186/12-FeatureExtract/feature_space.png"
courseSlug: "ap186"
created: "2019-10-24T12:02:00.0000Z"

alphabet: abcdefghijklmnopqrstuvwxyz

spaceData:
  [
    { url: "ab_space", caption: "a*-b*", key: "fig-ab-space" },
    { url: "ae_space", caption: "a*-e", key: "fig-ae-space" },
    { url: "be_space", caption: "b*-e", key: "fig-be-space" },
  ]
---

import { buildCldUrl } from "@/actions/_utils/cloudinary.client";

For this activity [[1](#Soriano2019)], I obtained the Fruits-360 dataset from Kaggle [[2](#Muresan2018)] which contains
thousands of labeled fruit images under the same lighting and capture settings but with varying angles. I took 50
samples each from the set of apples, oranges, and bananas.

#### Feature extraction: $L^*a^*b^*$ color space

I first imported the images into Python and converted them to $L^*a^*b^*$ color space. For each image, I extracted the
mean values from the $a^*$ and $b^*$ channels. The $a^*$ channel represents a chromaticity from green to red, while the
$b^*$ channel represents a chromaticity from blue to yellow.

#### Feature extraction: eccentricity $e$

Using the same images, I applied Otsu's method since the images contain only one fruit on a plain white background. Each
fruit is then easily detected as a single large blob. I then used the `regionprops` function to extract the eccentricity
property from each detected blob. An $e = 0$ corresponds to a perfect circle, while an $e = 1$ corresponds to a
parabola. Values $0 < e < 1$ are ellipses.

#### Discussion

Figure&nbsp;[1](#fig-feature-space) shows the feature space of the selected dataset in $a^*$, $b^*$, and $e$. We can observe
that all the classes show distinct clustering. The projections on each of the planes are shown in
Fig.&nbsp;[2](#fig-projections). The banana cluster shows a large variation in eccentricity but mostly resides in
high-eccentricity space. This can be attributed to the various rotations of the banana images, but are still
significantly elongated compared to the other fruit classes. Apples and oranges overlap in $a^*$ space (red and orange
have very close chromaticities), but can be separated in the $b^*$-$e$ space (orange is closer to yellow than red is;
apples are less rounded compared to oranges). If we needed to reduce the complexity, it is sufficient to choose between
either $a^*$-$b^*$ or $b^*$-$e$ feature spaces, though the former appears to maximize the class separation.

<figure id="fig-feature-space" class="container">
  <img
    src={buildCldUrl(`svip/186/12-FeatureExtract/feature_space.png`)}
    alt="feature space"
    class="mx-auto"
  />
  <figcaption class="text-center">
    Figure 1: Feature space in $a^*$, $b^*$, and $e$ of apples, bananas, and
    oranges.
  </figcaption>
</figure>

<figure id="fig-segment" class="container grid grid-cols-3 gap-4">
  {frontmatter.spaceData.map((d, index) => (
    <figure id={d.key}>
      <img
        src={buildCldUrl(`svip/186/12-FeatureExtract/${d.url}`)}
        alt={d.caption}
      />
      <figcaption class="text-center">
        ({frontmatter.alphabet[index]}) {d.caption}
      </figcaption>
    </figure>
  ))}
  <figcaption class="col-span-3 text-center">
    Figure 2: Feature space projections on different planes.
  </figcaption>
</figure>

#### References

<ol className="reference">
  <li id="Soriano2019">M. N. Soriano, _A12 - Feature extraction_ (2019).</li>
  <li id="Muresan2018">
    H. Muresan, and M. Oltean, Fruit recognition from images using deep
    learning. _Acta Univ. Sapientiae, Informatica_ **10**(1), 26-42 (2018).
  </li>
</ol>
