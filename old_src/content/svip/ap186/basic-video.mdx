---
title: "Activity 11: Basic Video Processing"
keywords:
  - image processing
  - video processing
  - computer vision
  - gravitational acceleration
  - kinematic motion
cover: "svip/186/11-BasicVideo/cover.png"
courseSlug: "ap186"
created: "2019-10-15T14:08:00.0000Z"

alphabet: abcdefghijklmnopqrstuvwxyz

segmentData:
  [
    { url: "0.png", caption: "frame 1", key: "seg-0" },
    { url: "9.png", caption: "frame 10", key: "seg-9" },
    { url: "18.png", caption: "frame 19", key: "seg-18" },
    { url: "22.png", caption: "frame 23", key: "seg-22" },
    { url: "28.png", caption: "frame 29", key: "seg-28" },
  ]
---

import { buildCldUrl } from "@/actions/_utils/cloudinary.client";

#### Experimental phase

For this activity [[1](#Soriano2019)], I paired up with [Rene Principe](mailto:rprincipe@nip.upd.edu.ph) and we decided to perform a simple experiment to
obtain the acceleration due to gravity. We used a Nikon D3400 with a SIGMA 24-70mm lens. We set it to ISO 200, f/2.8,
recording at 1080p60 at 50mm to minimize any vignetting or lens distortion. We placed the camera on a tripod at a fixed
distance away from a uniformly-lit wall and dropped a bright pink ball from rest such that its centroid was roughly
aligned with the upper edge of the frame, and was allowed to freely fall. The bottom edge of the frame was aligned with
the corner of the wall. The room was closed and there was no airconditioning, so we can assume that there are no
significant forces pushing it away from its plane of fall. Using a caliper, the ball was determined to have a diameter
of 6.5 cm.

#### Computational phase

##### Preprocessing

The raw video files were first trimmed in Adobe Premiere Pro such that the clip starts at the moment the ball is dropped
and ends either when the ball stops bouncing or goes out of the frame. The video was then rotated into portrait mode
such that the ground direction is downwards. Finally, it was exported as MP4. The original, unsegmented video is shown
below:

<iframe
  src="https://drive.google.com/file/d/16IaBhmNCL8T7cAKvIIQ6y4vyOT1K08hK/preview"
  width="640"
  height="480"
  allow="autoplay"
  class="mx-auto"
/>

##### Segmentation and morphological cleaning

Using Python, I first read an arbitrary frame such that the entire ball can be seen in the frame. Using my code for a
previous activity on [non-parametric segmentation](/svip/ap186/image-segmentation), I selected the ROI such that it
encompassed a rectangular portion of the ball, taking care not to include the background. After obtaining the ROI and
its histogram, non-parametric segmentation can automatically detect the ball for all succeeding frames. Next, I applied
Otsu's method to binarize the frames, followed by an elliptical closing operator of size 11 $\times$ 11. I then used the
`regionprops` function from the `skimage` library to obtain the segmented ball's properties per frame, in particular the
centroid and diameter properties. The result of these operations is shown in Fig.&nbsp;[1](#fig-segment).

<figure id="fig-segment" class="container grid grid-cols-5 gap-4">
  {frontmatter.segmentData.map((d, index) => (
    <figure id={d.key}>
      <img
        src={buildCldUrl(`svip/186/11-BasicVideo/${d.url}`)}
        alt={d.caption}
      />
      <figcaption class="text-center">
        ({frontmatter.alphabet[index]}) {d.caption}
      </figcaption>
    </figure>
  ))}
  <figcaption class="col-span-5 text-center">
    Figure 1: Representative frames as a result of successful segmentation and
    morphological cleaning. Notice in the middle frames that the ball appears to
    be squashed. This is due to the motion blur along the vertical, and in this
    case, the color of the ball starts to "blend" with the background. During
    this phenomenon, we measure the diameter horizontally, since there is no
    motion blur along this dimension.
  </figcaption>
</figure>

##### Calibration

The diameter of the ball was averaged for the first 30 frames (just before it bounces for the first time), and using the
actual diameter obtained earlier, its pixel-to-length calibration is as follows:

<span id="eq-calibration" class="mx-auto">
$
\begin{equation}
  \mathrm{meters = pixels \times \frac{diameter (meters)}{diameter (pixels)}}
\end{equation}
$
</span>

Thus, the position of the ball in real units at any time can be obtained, and its velocity and acceleration can be
computed using central difference algorithm. Its motion curves are shown in Fig.&nbsp;[2](#fig-motion).

<figure id="fig-motion" class="container">
  <img
    src={buildCldUrl(`svip/186/11-BasicVideo/motion.png`)}
    alt="motion calibration"
  />
  <figcaption class="text-center">
    Figure 2: Position, velocity & acceleration curves of the free-falling ball.
  </figcaption>
</figure>

##### Obtaining $g$

Calculating the acceleration due to gravity $g$ can be done in two ways. First, we can isolate the position curve up to
the point when it first bounces (first 30 frames), and fit this curve to an equation of the form

<span id="eq-curve-fit" class="mx-auto">
  $ \begin{equation}
  f(t; g, v_0, x_0) = gt^2 + v_0 t + x_0 \end{equation}$
</span>

via nonlinear least-squares fitting. Using this method, we obtain a value of $\boxed{g = -9.68 \textrm{ m/s}^2}$, which
deviates by 1.31\% from the theoretical. For reference, the theoretical value is $g = -9.81$ m/s<sup>2</sup>.

Another way this can be done is by taking again the first 30 frames and averaging their acceleration values which we
obtained earlier. This method yields $\boxed{g = -9.61 \textrm{ m/s}^2}$, which deviates by 2.04\% from the theoretical.

#### References

<ol className="reference">
  <li id="Soriano2019">
    M. N. Soriano, _A11 - Basic video processing_ (2019).
  </li>
</ol>
